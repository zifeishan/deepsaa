deepdive {

  # #############
  # CONFIGURATION
  # #############
  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}  #"
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  sampler.sampler_cmd: "util/sampler-dw-linux gibbs"
  sampler.sampler_args: "-l 300 -s 1 -i 300 -a 0.1"
  # sampler.sampler_args: "-l 300 -s 1 -i 500 --alpha 0.001"
  # sampler.sampler_args: "-l 0 -s 1 -i 0 --alpha 0.01"

  # pipeline.relearn_from: "/lfs/madmax2/0/zifei/deepdive/out/2014-04-28T152335/"

  # ###########
  # CALIBRATION
  # ###########
  # calibration.holdout_fraction: 0.25

  # Unknown pubs, guess both pubs and sentences
  calibration.holdout_query: """
    INSERT INTO dd_graph_variables_holdout(variable_id) 
      SELECT id FROM publication_author
      WHERE publication_id IN (select * from holdout_publications);

    INSERT INTO dd_graph_variables_holdout(variable_id) 
      SELECT id FROM sentence_author
      WHERE publication_id IN (select * from holdout_publications);
     """

  # ##############
  # FREE VARIABLES
  # ##############
  schema.variables {
    publication_author.is_true: Boolean
    sentence_author.is_true: Boolean
  }

  # ###########
  # DEBUGGING
  # ###########
  pipeline.run: "imported"

  # All we need is just to run "bash preprocess/import... then run"
  pipeline.pipelines.imported: [

    ########################################################
    ########### IMPORTED FROM SUPV AUTHOR LIST #############
    ########################################################

    # # "ext_supv_author_list", # not used for now...
    # "ext_prepare_supervision",

    ########################################################
    ################### IMPORTED FROM FILELIST #############
    ########################################################

    ########## DANGER ZONE!!!! ##########
    # # "ext_load_files",
    # # "ext_sentences_nlp_para_nltk",

    # # "ext_prepare_authors_form_namelist",

    # # Filter negative examples or it is too large
    # "ext_sentence_author_empty",
    # "ext_publication_author_empty",
    
    # "ext_positive_example",
    # "ext_negative_example",

    ########################################################
    ######### IMPORTED FROM TOY DATASET PARARGRAPHS ########
    ########################################################

    ####### NLP extraction ###########
    # "ext_sentences_nlp_para",

    ###### Prepare supervision ######
    # "ext_sentence_author",
    # "ext_publication_author",
    # "ext_imported_sentences_labeling",

    ##########################
    ######### GENERAL ########
    ##########################

    # ####### Other extraction ###########
    

    # # # Features
    # "ext_sentence_stats",
    # "ext_stopwords",
    # "ext_funcword_1gram",
    # "ext_funcword_2gram",
    # "ext_non_dict_words",
    # "ext_punc_seq",
    # "ext_char_1gram",
    # "ext_char_2gram",
    # "ext_char_3gram",
    # "ext_word_1gram",
    # "ext_word_3gram",
    # "ext_pos_1gram",
    # "ext_pos_2gram",
    # "ext_dep",  # Dependency path
    # "ext_pos_dep",  # Not implemented yet

    # # Export features
    "ext_export_json_sentence",
    "ext_export_json_sentence_copy",
    "ext_export_json_pub",
    "ext_export_json_pub_copy",

    ################ INFERENCE #################

    # # Doc level inference
    # # "f_doc_stats",

    # # Joint inference
    # "f_pub_sent_author",
    # "f_near_sent_same_author",
    # "f_pub_author_constraint",
    # # "f_sent_author_constraint",  # Too many

    # # Sentence level inference
    # # "fs_sent_stats",
    # # "fs_char_1gram",
    # # "fs_char_2gram",
    # "fs_word_1gram",
    # # "fs_word_3gram",
    # # "fs_pos_1gram",
    # # "fs_pos_2gram",
    # # "fs_dep_1gram",

    # # Sentence level inference
    # # "f_doc_stats",
    # # "f_char_1gram",
    # # "f_char_2gram",
    # # "f_word_1gram",
    # # "f_word_3gram",

  ]


  # ##########
  # Extractors
  # ##########
  extraction.extractors {

    ########### 
    # Prepare tables before extraction:
    # corpus(id bigint): Contains all publication ids we care. 
    # authors(author_id bigint): Contains all author_id we care. 

    # Extract sentence NLP Tags from (imported_)paragraphs
    ext_load_files {
      style: "tsv_extractor"
      input: """
          SELECT  m.id AS publication_id, path
          FROM    meta_publications m, document_paths p
          WHERE   m.arxiv_id = p.arxiv_id
        """
      output_relation: "paragraphs"
      udf: "pypy "${APP_HOME}"/udf/ext_load_files.py"
      before: ${APP_HOME}"/udf/before_load_file.sh"
      after: util/fill_sequence.sh paragraphs paragraph_id
      parallelism: ${PARALLELISM}
      input_batch_size: 100
    }

    # Extract sentence NLP Tags from (imported_)paragraphs
    ext_sentences_nlp_para_nltk {
      style: "plpy_extractor"
      input: """
          SELECT    document_id, pid, paragraph_id, paragraph
          FROM      paragraphs
        """
      output_relation: "sentences"
      udf: ${APP_HOME}"/udf/nltk_extractor/run.py"
      before: ${APP_HOME}"/udf/before_sentences.sh"
      after: util/fill_sequence.sh sentences sentence_id
      dependencies: ["ext_load_files"]
    }
    # Extract sentence NLP Tags from (imported_)paragraphs
    ext_sentences_nlp_para {
      input: """
          SELECT    paragraph_id, paragraph
          FROM      paragraphs
        """
      output_relation: "paragraph_sentences"
      udf: "bash "${APP_HOME}"/udf/nlp_extractor/run.sh -k paragraph_id -v paragraph -l 20 -t 4"
      before: ${APP_HOME}"/udf/before_paragraph_sentences.sh"
      after: ${APP_HOME}"/udf/after_sentences.sh"
      input_batch_size: 10
      output_batch_size: 1000
      parallelism: ${PARALLELISM}
      dependencies: ["ext_load_files"]
    }

    # Extract sentence NLP Tags from articles
    ext_sentences_nlp {
      input: """
          SELECT p.id AS publication_id,
                description
          FROM meta_publications p, corpus t
          WHERE p.id = t.id and 
            not exists (select * from sentences where document_id = p.id)
          ORDER BY publication_id ASC
        """
      output_relation: "sentences"
      udf: "bash "${APP_HOME}"/udf/nlp_extractor/run.sh -k publication_id -v description -l 20 -t 4"
      before: ${APP_HOME}"/udf/before_sentences.sh"
      after: ${DEEPDIVE_HOME}"/examples/spouse_example/script/fill_sequence.sh sentences sentence_id"
      input_batch_size: 10
      output_batch_size: 1000
      parallelism: ${PARALLELISM}
    }


    ext_prepare_authors_form_namelist {
      style: "plpy_extractor"
      input: """
        select distinct author_names from document_paths;
      """
      output_relation: "author_names"
      udf: ${APP_HOME}"/udf/ext_author_names.py"
      before: ${APP_HOME}"/udf/before_author_names.sh"
      after: ${APP_HOME}"/udf/after_author_names.sh"
    }

    # ext_holdout_document {
    #   style: "sql_extractor"
    #   sql: """
    #     DROP TABLE IF EXISTS holdout_publications;

    #     SELECT  id AS publication_id 
    #     INTO    holdout_publications
    #     FROM    corpus
    #     WHERE   random() < 0.25;
    #   """
    #   dependencies: ["ext_sentences_nlp_para", "ext_sentences_nlp"]
    # }

    # Prepare "supervised_author_names" table before this
    # Select all authors in the list, and their co-authors
    ext_supv_author_list {
      style: "sql_extractor"
      sql: """
        DROP TABLE IF EXISTS authors CASCADE;

        SELECT id as author_id, name
        INTO authors 
        FROM meta_authors 
        WHERE name IN (select name from supervised_author_names);

        DROP TABLE IF EXISTS corpus CASCADE;

        SELECT  distinct publication_id as id 
        INTO    corpus
        FROM    publication_authors 
        WHERE   author_id in (select author_id from authors);

        INSERT INTO authors
        SELECT  distinct meta_authors.id, meta_authors.name
        FROM    publication_authors m,
                corpus c,
                meta_authors
        WHERE   m.publication_id = c.id
          AND   meta_authors.id = m.author_id
          AND   NOT EXISTS (
              SELECT * FROM authors 
              WHERE authors.author_id = m.author_id)

      """
    }


    # Create the prediction matrix
    # TODO Fix bigserial for faster grounding 
    # TODO: sentence_id column name
    # DISTRIBUTED BY (publication_id);
    ext_sentence_author {
      style: "sql_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para",  "ext_supv_author_list", "ext_prepare_authors_form_namelist"]
      sql: """
        DROP TABLE IF EXISTS sentence_author CASCADE;

        CREATE TABLE sentence_author (
            publication_id bigint,
            sentence_id bigint,
            author_id bigint,
            is_true boolean,
            id bigint
          );

        INSERT INTO sentence_author (sentence_id, publication_id, 
                author_id)
        SELECT  sentence_id, 
                document_id AS publication_id, 
                authors.author_id
          FROM  sentences, authors;
      """
    }

    # Create the prediction matrix
    ext_publication_author {
      style: "sql_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para",  "ext_supv_author_list", "ext_prepare_authors_form_namelist"]
      sql: """
        DROP TABLE IF EXISTS publication_author CASCADE;

        CREATE TABLE publication_author (
            publication_id bigint,
            author_id bigint,
            is_true boolean,
            id bigint
          ) DISTRIBUTED BY (publication_id);

        INSERT INTO publication_author (publication_id, 
                author_id, is_true)
        SELECT  corpus.id AS publication_id, 
                authors.author_id,
                null::boolean is_true
          FROM  corpus, authors;
      """
    }



    # Create the prediction matrix
    # TODO Fix bigserial for faster grounding 
    # TODO: sentence_id column name
    # DISTRIBUTED BY (publication_id);
    ext_sentence_author_empty {
      style: "sql_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para",  "ext_supv_author_list", "ext_prepare_authors_form_namelist"]
      sql: """
        DROP TABLE IF EXISTS sentence_author CASCADE;

        CREATE TABLE sentence_author (
            publication_id bigint,
            sentence_id bigint,
            author_id bigint,
            is_true boolean,
            id bigint
          );
      """
    }

    # Create the prediction matrix
    ext_publication_author_empty {
      style: "sql_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para",  "ext_supv_author_list", "ext_prepare_authors_form_namelist"]
      sql: """
        DROP TABLE IF EXISTS publication_author CASCADE;

        CREATE TABLE publication_author (
            publication_id bigint,
            author_id bigint,
            is_true boolean,
            id bigint
          ) DISTRIBUTED BY (publication_id);
      """
    }

    # DRPRECATED. Users have to prepare "publication_authors" beforehand.
    # # TODO meta_publication_authors -> publication_authors
    # ext_prepare_supervision {
    #   style: "sql_extractor"
    #   dependencies: ["ext_sentence_author", "ext_publication_author"]
    #   sql:"""
    #     DROP TABLE IF EXISTS publication_authors CASCADE;
    #     CREATE TABLE publication_authors AS 
    #     SELECT p.*
    #     FROM publication_authors p, corpus t 
    #     WHERE t.id = p.publication_id
    #     DISTRIBUTED BY (publication_id);
    #     """
    # }


    # For non-paragraph import:
        # UPDATE  sentence_author 
        #    SET  is_true = true
        #   FROM  sentences s,
        #         meta_authors
        #  WHERE  sentence_author.publication_id = s.document_id
        #    AND  sentence_author.sentence_id = s.sentence_id
        #    AND  author_id = meta_authors.id
        #    AND  author_name = meta_authors.name;

    ext_imported_sentences_labeling {
      style: "sql_extractor"
      dependencies: ["ext_sentence_author", "ext_publication_author"]
      sql: """
        UPDATE  sentence_author 
           SET  is_true = true
          FROM  sentences s,
                paragraphs p,
                meta_authors
         WHERE  sentence_author.publication_id = s.document_id
           AND  s.document_id = p.document_id
           AND  s.paragraph_id = p.paragraph_id
           AND  sentence_author.sentence_id = s.sentence_id
           AND  author_id = meta_authors.id
           AND  author_name = meta_authors.name;

        UPDATE  sentence_author 
           SET  is_true = false
         WHERE  is_true is null;

        UPDATE  publication_author
           SET  is_true = true
          FROM  publication_authors pa
         WHERE  publication_author.publication_id = pa.publication_id
           AND  publication_author.author_id = pa.author_id;
           
        UPDATE  publication_author
           SET  is_true = false
         WHERE  is_true is null;
      """
    }

    # Set Single_author_papers as positive examples
    # 7713041 positive examples, (sent level) 
    # by 857 authors and 5196 papers
    ext_positive_example {
      style: "sql_extractor"
      dependencies: ["ext_prepare_supervision", "ext_sentence_author", "ext_publication_author", "ext_sentence_author_empty", "ext_publication_author_empty"]
      sql: """
        DROP TABLE IF EXISTS publication_author_count CASCADE;

        CREATE TABLE publication_author_count 
        AS 
          SELECT t.id AS publication_id, COUNT(author_id) AS num_authors FROM corpus t, publication_authors 
        WHERE t.id = publication_id GROUP BY (t.id) 
        DISTRIBUTED BY (publication_id);

        INSERT INTO sentence_author(publication_id, sentence_id, author_id, is_true)
        SELECT  a.publication_id, 
                s.sentence_id, 
                a.author_id, 
                true
          FROM  publication_author_count c,
                publication_authors a,
                sentences s
         WHERE  a.publication_id = c.publication_id
           AND  s.document_id = a.publication_id
           AND  c.num_authors = 1 ;

        INSERT INTO publication_author(publication_id, author_id, is_true)
        SELECT  a.publication_id, 
                a.author_id, 
                true
          FROM  publication_authors a;

      """
    }

    # Set ALL non-authored papers as negative examples
    # Coauthor(a,b), paper(p), author(a,p), !author(b,p) -> neg(b,p)
    # Coauthor(a,b), paper(p), author(a,p), !author(b,p) -> neg(b,s) for some s in p.
    ext_negative_example {
      style: "sql_extractor"
      dependencies: ["ext_prepare_supervision", "ext_sentence_author", "ext_publication_author", "ext_sentence_author_empty", "ext_publication_author_empty"]
      sql: """

          DROP TABLE IF EXISTS coauthor;

          CREATE TABLE coauthor AS
          SELECT  pa1.author_id as author1, 
                  pa2.author_id as author2
            FROM  publication_authors pa1,
                  publication_authors pa2
           WHERE  pa1.publication_id = pa2.publication_id
             AND  pa1.author_id != pa2.author_id
        GROUP BY  pa1.author_id, pa2.author_id;

          INSERT INTO publication_author(publication_id, author_id, is_true)
          SELECT  pa1.publication_id, 
                  author2,
                  false
            FROM  publication_authors pa1,
                  coauthor
           WHERE  pa1.author_id = author1
             AND  NOT EXISTS 
                 (SELECT * 
                  FROM   publication_authors pa2
                  WHERE  author2 = pa2.author_id
                    AND  pa2.publication_id = pa1.publication_id)
          ORDER BY random()
          limit 1000000;

          INSERT INTO sentence_author(publication_id, sentence_id, author_id, is_true)
          SELECT  pa.publication_id, 
                  s.sentence_id,
                  pa.author_id,
                  false
            FROM  publication_author pa,
                  sentences s
           WHERE  pa.is_true = false
             AND  pa.publication_id = s.document_id
          ORDER BY random()
          limit 10000000;
      """
        # How to optimize??
          #       INSERT INTO sentence_author(publication_id, sentence_id, author_id, is_true)
          # SELECT  pa.publication_id, 
          #         array_agg(s.sentence_id),
          #         pa.author_id,
          #         false
          #   FROM  publication_author pa,
          #         sentences s
          #  WHERE  pa.is_true = false
          #    AND  pa.publication_id = s.document_id
          # GROUP BY pa.publication_id, pa.author_id
          # limit 10;

      # For small data
        # UPDATE  sentence_author 
        #    SET  is_true = false
        #  WHERE  NOT EXISTS (
        #     SELECT  * 
        #     FROM    publication_authors a
        #     WHERE   a.publication_id =  sentence_author.publication_id
        #       AND   a.author_id = sentence_author.author_id
        # );

        # UPDATE  publication_author 
        #    SET  is_true = false
        #  WHERE  NOT EXISTS (
        #     SELECT  * 
        #     FROM    publication_authors a
        #     WHERE   a.publication_id =  publication_author.publication_id
        #       AND   a.author_id = publication_author.author_id
        # );
    }


    ext_sentence_stats {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, sentence, words
        from sentences
      """
      output_relation: "f_sentence_stats"
      udf: ${APP_HOME}"/udf/ext_sentence_stats.py"
      before: ${APP_HOME}"/udf/before_sent_feature.sh sentence_stats"
    }

    # Select character Ngrams (N is 3rd input in the query)
    ext_stopwords {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, words
        from sentences
      """
      output_relation: "f_stopword_1gram"
      udf: ${APP_HOME}"/udf/ext_stopwords.py"
      before: ${APP_HOME}"/udf/before_ngram.sh stopword_1"
    }

    ext_funcword_1gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, words, pos_tags, 1 as gram_len
        from sentences
      """
      output_relation: "f_funcword_1gram"
      udf: ${APP_HOME}"/udf/ext_funcword_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh funcword_1"
    }

    ext_funcword_2gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, words, pos_tags, 2 as gram_len
        from sentences
      """
      output_relation: "f_funcword_2gram"
      udf: ${APP_HOME}"/udf/ext_funcword_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh funcword_2"
    }

    ext_non_dict_words {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, words
        from sentences
      """
      output_relation: "f_non_dict_words"
      udf: ${APP_HOME}"/udf/ext_spell_errors.py"
      before: ${APP_HOME}"/udf/before_sent_feature.sh non_dict_words"
    }

    ext_punc_seq {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, words, pos_tags
        from sentences
      """
      output_relation: "f_punc_seq"
      udf: ${APP_HOME}"/udf/ext_punc_seq.py"
      before: ${APP_HOME}"/udf/before_sent_feature.sh punc_seq"
    }

    # Select character Ngrams (N is 3rd input in the query / before / output_relation)
    ext_char_1gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, sentence, 1 as gram_len
        from sentences
      """
      output_relation: "f_char_1gram"
      udf: ${APP_HOME}"/udf/ext_char_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh char_1"
    }

    # Select character Ngrams (N is 3rd input in the query / before / output_relation)
    ext_char_2gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, sentence, 2 as gram_len
        from sentences
      """
      output_relation: "f_char_2gram"
      udf: ${APP_HOME}"/udf/ext_char_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh char_2"
    }

    # Select character Ngrams (N is 3rd input in the query / before / output_relation)
    ext_char_3gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, sentence, 3 as gram_len
        from sentences
      """
      output_relation: "f_char_3gram"
      udf: ${APP_HOME}"/udf/ext_char_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh char_3"
    }

    # Select character Ngrams (N is 3rd input in the query)
    ext_word_1gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, words, 1 as gram_len
        from sentences
      """
      output_relation: "f_word_1gram"
      udf: ${APP_HOME}"/udf/ext_word_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh word_1"
    }

    # Select word Ngrams (N is 3rd input in the query)
    ext_word_3gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select sentence_id, document_id, words, 3 as gram_len
        from sentences
      """
      output_relation: "f_word_3gram"
      udf: ${APP_HOME}"/udf/ext_word_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh word_3"
    }


    ext_pos_1gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select  sentence_id, document_id, 
                pos_tags as words, 
                1 as gram_len
        from sentences
      """
      output_relation: "f_pos_1gram"
      udf: ${APP_HOME}"/udf/ext_word_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh pos_1"
    }
    ext_pos_2gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select  sentence_id, document_id, 
                pos_tags as words, 
                2 as gram_len
        from sentences
      """
      output_relation: "f_pos_2gram"
      udf: ${APP_HOME}"/udf/ext_word_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh pos_2"
    }

    # Select pos Ngrams (N is 3rd input in the query)
    ext_dep {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select  sentence_id, document_id, 
                dependencies as words, 
                1 as gram_len
        from sentences      
        WHERE dependencies[1] not like 'dep%'
        """
      output_relation: "f_dep_1gram"
      udf: ${APP_HOME}"/udf/ext_word_ngram.py"
      before: ${APP_HOME}"/udf/before_ngram.sh dep_1"
    }

    ############# Document-level ##############

    # Doc length, # words, avg length of words.
    ext_doc_stats {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
      input: """
        select id, datestamp, title, description 
        from corpus natural join meta_publications
      """
      output_relation: "f_doc_stats"
      udf: ${APP_HOME}"/udf/ext_doc_stats.py"
      before: ${APP_HOME}"/udf/before_doc_stats.sh"
    }

    # ext_doc_stats_toy_corpus {
    #   style: "plpy_extractor"
    #   dependencies: ["ext_sentences_nlp", "ext_sentences_nlp_para"] 
    #   input: """
    #     select id, '', '', array_agg(sentence) TODO!!

    #     from sentence, corpus natural join meta_publications
    #   """
    #   output_relation: "f_doc_stats"
    #   udf: ${APP_HOME}"/udf/ext_doc_stats.py"
    #   before: ${APP_HOME}"/udf/before_doc_stats.sh"
    # }

    ########### EXPORT JSON BY SENTENCE #############

    ext_export_json_sentence {
      style: "plpy_extractor"
      dependencies: ["ext_sentence_stats", "ext_char_1gram", "ext_char_2gram", "ext_char_3gram", "ext_word_1gram", "ext_word_3gram", "ext_pos_1gram", "ext_pos_2gram", "ext_dep", "ext_doc_stats", "ext_imported_sentences_labeling"]
      output_relation: "export_features"
      udf: ${APP_HOME}"/udf/ext_export_json.py"
      before: ${APP_HOME}"/udf/before_export_json.sh"

          # (SELECT s.id as sentence_id, 
          #         s.document_id as publication_id,
          #         'doc' as fname_prefix, 
          #         array_agg(fname) as fname, 
          #         array_agg(fval) as fval
          #   FROM  f_doc_stats f,
          #         sentences s
          #   WHERE f.publication_id = s.document_id
          #   GROUP BY s.document_id, s.id)
          # UNION ALL

        ###### WORD LEVEL FEATURES
          # UNION ALL
          # (SELECT sentence_id, publication_id,
          #         'w1' as fname_prefix, 
          #         array_agg(ngram) as fname,
          #         array_agg(count) as fval
          #   FROM  f_word_1gram 
          #   GROUP BY publication_id, sentence_id)

          # UNION ALL
          # (SELECT sentence_id, publication_id,
          #         'w3' as fname_prefix, 
          #         array_agg(ngram) as fname,
          #         array_agg(count) as fval
          #   FROM  f_word_3gram
          #   GROUP BY publication_id, sentence_id)

          # UNION ALL
          # (SELECT sentence_id, publication_id,
          #         'dep' as fname_prefix, 
          #         array_agg(ngram) as fname,
          #         array_agg(count) as fval
          #   FROM  f_dep_1gram
          #   GROUP BY publication_id, sentence_id)

      input: """
      SELECT 
        sentence_id,
        publication_id,
        fname_prefix,
        fname,
        fval
        FROM 
        (

          (SELECT sentence_id, publication_id,
                  'sen' as fname_prefix, 
                  array_agg(fname) as fname, 
                  array_agg(fval)  as fval
            FROM  f_sentence_stats
            GROUP BY publication_id, sentence_id)
          UNION ALL
          
          (SELECT sentence_id, publication_id, 
                  'c1' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_char_1gram 
            GROUP BY publication_id, sentence_id)
          UNION ALL
          (SELECT sentence_id, publication_id,
                  'c2' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_char_2gram 
            GROUP BY publication_id, sentence_id)
          UNION ALL
          (SELECT sentence_id, publication_id,
                  'c3' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_char_3gram 
            GROUP BY publication_id, sentence_id)

          UNION ALL
          (SELECT sentence_id, publication_id,
                  'pos2' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_pos_2gram
            GROUP BY publication_id, sentence_id)
          UNION ALL
          (SELECT sentence_id, publication_id,
                  'pos1' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_pos_1gram
            GROUP BY publication_id, sentence_id)

          UNION ALL
          (SELECT sentence_id, publication_id,
                  'stopword1' as fname_prefix,
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_stopword_1gram
            GROUP BY publication_id, sentence_id)
          UNION ALL
          (SELECT sentence_id, publication_id,
                  'funcword1' as fname_prefix,
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_funcword_1gram
            GROUP BY publication_id, sentence_id)
          UNION ALL
          (SELECT sentence_id, publication_id,
                  'funcword2' as fname_prefix,
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_funcword_2gram
            GROUP BY publication_id, sentence_id)
          UNION ALL
          (SELECT sentence_id, publication_id,
                  'nondict' as fname_prefix,
                  array_agg(fname) as fname,
                  array_agg(fval) as fval
            FROM  f_non_dict_words
            GROUP BY publication_id, sentence_id)
          UNION ALL
          (SELECT sentence_id, publication_id,
                  'punc' as fname_prefix,
                  array_agg(fname) as fname,
                  array_agg(fval) as fval
            FROM  f_punc_seq
            GROUP BY publication_id, sentence_id)


        ) tmp
      """
    }

    ext_export_json_sentence_copy {
      style: "sql_extractor"
      dependencies: ["ext_export_json_sentence"]
      sql: """
        COPY(
            select * from export_features
            order by publication_id, sentence_id)
          to '/tmp/deepsaa-sentence-features.tsv';

        DROP TABLE IF EXISTS eval_sentence_authors CASCADE;

        SELECT sentence_id, publication_id, array_agg(distinct author_id) as authors 
        INTO eval_sentence_authors 
        FROM sentence_author where IS_TRUE != false or is_true is null group by publication_id, sentence_id;

        COPY(
          select * from eval_sentence_authors
            order by publication_id, sentence_id)
          to '/tmp/deepsaa-sentence-authors.tsv';

      """
    }

    ext_export_json_pub {
      style: "plpy_extractor"
      dependencies: ["ext_sentence_stats", "ext_char_1gram", "ext_char_2gram", "ext_char_3gram", "ext_word_1gram", "ext_word_3gram", "ext_pos_1gram", "ext_pos_2gram", "ext_dep", "ext_doc_stats", "ext_imported_sentences_labeling"]
      output_relation: "export_features_pub"
      # This UDF computes the SUM.
      udf: ${APP_HOME}"/udf/ext_export_json_pub.py"
      before: ${APP_HOME}"/udf/before_export_json_pub.sh"
          # (SELECT publication_id,
          #         'doc' as fname_prefix, 
          #         array_agg(fname) as fname, 
          #         array_agg(fval) as fval
          #   FROM  f_doc_stats f
          #   GROUP BY publication_id)
          # UNION ALL

        # Word level
          # UNION ALL
          # (SELECT publication_id,
          #         'w1' as fname_prefix, 
          #         array_agg(ngram) as fname,
          #         array_agg(count) as fval
          #   FROM  f_word_1gram 
          #   GROUP BY publication_id)
          # UNION ALL
          # (SELECT publication_id,
          #         'w3' as fname_prefix, 
          #         array_agg(ngram) as fname,
          #         array_agg(count) as fval
          #   FROM  f_word_3gram 
          #   GROUP BY publication_id)

      input: """
      SELECT 
        publication_id,
        fname_prefix,
        fname,
        fval
        FROM 
        (
          (SELECT publication_id,
                  'nondict' as fname_prefix,
                  array_agg(fname) as fname,
                  array_agg(fval) as fval
            FROM  f_non_dict_words
            GROUP BY publication_id)
          UNION ALL
          (SELECT publication_id,
                  'punc' as fname_prefix,
                  array_agg(fname) as fname,
                  array_agg(fval) as fval
            FROM  f_punc_seq
            GROUP BY publication_id)
          UNION ALL
          (SELECT publication_id,
                  'stopword1' as fname_prefix,
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_stopword_1gram
            GROUP BY publication_id)
          UNION ALL
          (SELECT publication_id,
                  'funcword1' as fname_prefix,
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_funcword_1gram
            GROUP BY publication_id)
          UNION ALL
          (SELECT publication_id,
                  'funcword2' as fname_prefix,
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_funcword_2gram
            GROUP BY publication_id)

          UNION ALL
          (SELECT publication_id, 
                  'c1' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_char_1gram 
            GROUP BY publication_id)
          UNION ALL
          (SELECT publication_id,
                  'c2' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_char_2gram 
            GROUP BY publication_id)
          UNION ALL
          (SELECT publication_id,
                  'c3' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_char_3gram 
            GROUP BY publication_id)

          UNION ALL
          (SELECT publication_id,
                  'pos2' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_pos_2gram
            GROUP BY publication_id)
          UNION ALL
          (SELECT publication_id,
                  'pos1' as fname_prefix, 
                  array_agg(ngram) as fname,
                  array_agg(count) as fval
            FROM  f_pos_1gram
            GROUP BY publication_id)

        ) tmp
      """
    }

    ext_export_json_pub_copy {
      style: "sql_extractor"
      dependencies: ["ext_export_json_pub"]
      sql: """
        COPY(
            select * from export_features_pub
            order by publication_id)
          to '/tmp/deepsaa-pub-features.tsv';

        DROP TABLE IF EXISTS eval_publication_authors CASCADE;

        SELECT publication_id, array_agg(distinct author_id) as authors 
        INTO eval_publication_authors
        FROM sentence_author where IS_TRUE != false or is_true is null GROUP BY publication_id;

        COPY(
          select * from eval_publication_authors
            order by publication_id)
          to '/tmp/deepsaa-pub-authors.tsv';

      """
    }
    # # Set ALL non-authored papers as negative examples
    # # 3539102 negative examples
    # ext_coauthorship {
    #   style: "sql_extractor"
    # }
  }

  # ###############
  # Inference Rules
  # ###############
  inference.factors {

    ############## Document level prediction ##############
    # f_doc_stats {
    #   input_query: """
    #       SELECT  pub.id as "publication_author.id",
    #               pub.is_true as "publication_author.is_true",
    #               (author_id || fname) as "f_doc_stats.fname"
    #       FROM    f_doc_stats f, 
    #               publication_author pub
    #       WHERE   pub.publication_id = f.publication_id AND
    #         (
    #             (fname = 'num_chars_title' and fval >= 58) OR
    #             (fname = 'num_chars' and fval >= 1111) OR
    #             (fname = 'avg_word_length' and fval >= 6.23) OR
    #             (fname = 'num_words' and fval >= 155) 
    #         )
    #       """
    #   function: "IsTrue(publication_author.is_true)"
    #   weight: "?(f_doc_stats.fname)"
    # }
    # # TODO these should not function at document level...
    # f_char_1gram {
    #   input_query: """
    #       SELECT  pub.id as "publication_author.id",
    #               pub.is_true as "publication_author.is_true",
    #               (author_id || ngram) as "f_char_1gram.ngram"
    #       FROM    f_char_1gram f, 
    #               publication_author pub
    #       WHERE   count > 100.0
    #         AND   pub.publication_id = f.publication_id
    #       """
    #   function: "IsTrue(publication_author.is_true)"
    #   weight: "?(f_char_1gram.ngram)"
    # }
    # f_char_2gram {
    #   input_query: """
    #       SELECT  pub.id as "publication_author.id",
    #               pub.is_true as "publication_author.is_true",
    #               (author_id || ngram) as "f_char_2gram.ngram"
    #       FROM    f_char_2gram f, 
    #               publication_author pub
    #       WHERE   count > 20.0
    #         AND   pub.publication_id = f.publication_id
    #       """
    #   function: "IsTrue(publication_author.is_true)"
    #   weight: "?(f_char_2gram.ngram)"
    # }
    # f_word_1gram {
    #   input_query: """
    #       SELECT  pub.id as "publication_author.id",
    #               pub.is_true as "publication_author.is_true",
    #               (author_id || ngram) as "f_word_1gram.ngram"
    #       FROM    f_word_1gram f, 
    #               publication_author pub
    #       WHERE   count > 3.0
    #         AND   pub.publication_id = f.publication_id
    #       """
    #   function: "IsTrue(publication_author.is_true)"
    #   weight: "?(f_word_1gram.ngram)"
    # }
    # f_word_3gram {
    #   input_query: """
    #       SELECT  pub.id as "publication_author.id",
    #               pub.is_true as "publication_author.is_true",
    #               (author_id || ngram) as "f_word_3gram.ngram"
    #       FROM    f_word_3gram f, 
    #               publication_author pub
    #       WHERE   count > 2.0
    #         AND   pub.publication_id = f.publication_id
    #       """
    #   function: "IsTrue(publication_author.is_true)"
    #   weight: "?(f_word_3gram.ngram)"
    # }

    #################### Joint inference Rules ################

    # Sentence author should be a publication author
    # # Reduce #factors: only count each paragraph's first sentence
    # # AND   sent.sentence_offset = 0
    # Only to balance weights for better performance...
    f_pub_sent_author {
      input_query: """
          SELECT  s.id as "sentence_author.id",
                  p.id as "publication_author.id",
                  s.is_true as "sentence_author.is_true",
                  p.is_true as "publication_author.is_true"
          FROM    sentence_author s, 
                  sentences sent,
                  publication_author p 
          WHERE   s.publication_id = p.publication_id
            AND   s.publication_id = sent.document_id
            AND   s.sentence_id = sent.sentence_id
            AND   s.author_id = p.author_id 
            AND   sent.sentence_offset = 0
          ;
          """
      # If he is a sentence author, he must be a publication author
      function: "Imply(sentence_author.is_true, publication_author.is_true)"
      weight: "10"  # Fixed weight
      # Is it good to use 10 here? or 1? TODO
    }

    # Near sentences are written by same author inside a paragraph
    f_near_sent_same_author {
      input_query: """
          SELECT  sa1.id as "sentence_author.sa1.id",
                  sa2.id as "sentence_author.sa2.id",
                  sa1.is_true as "sentence_author.sa1.is_true",
                  sa2.is_true as "sentence_author.sa2.is_true"
          FROM    sentence_author sa1,
                  sentence_author sa2,
                  sentences s1,
                  sentences s2
          WHERE   s1.document_id = s2.document_id
            AND   sa1.publication_id = sa2.publication_id
            AND   sa1.publication_id = s1.document_id
            AND   sa1.sentence_id = s1.sentence_id
            AND   sa2.sentence_id = s2.sentence_id
            AND   sa1.author_id = sa2.author_id
            AND   s1.pid = s2.pid
            AND   s1.sentence_offset + 1 = s2.sentence_offset
          """
      # Same paragraph should be written by a same author.
      function: "Equal(sentence_author.sa1.is_true, sentence_author.sa2.is_true)"
      weight: "10"  # Fixed weight is cheating here..
      # weight: "?"
    }

    # one pub should have few authors... Not sure
    f_pub_author_constraint {
      input_query: """
          SELECT  pa1.id as "publication_author.pa1.id",
                  pa2.id as "publication_author.pa2.id",
                  pa1.is_true as "publication_author.pa1.is_true",
                  pa2.is_true as "publication_author.pa2.is_true"
          FROM    publication_author pa1,
                  publication_author pa2
          WHERE   pa1.publication_id = pa2.publication_id
            AND   pa1.author_id != pa2.author_id
          """
      function: "And(publication_author.pa1.is_true, publication_author.pa2.is_true)"
      # weight: "-0.5"  # should be a small negative weight..?
      weight: "?"  # should be a small negative weight..?
    }

    # # Needs multinomial?
    # # Duplicated? too many...
    # f_sent_author_constraint {
    #   input_query: """
    #       SELECT  sa1.id as "sentence_author.sa1.id",
    #               sa2.id as "sentence_author.sa2.id",
    #               sa1.is_true as "sentence_author.sa1.is_true",
    #               sa2.is_true as "sentence_author.sa2.is_true"
    #       FROM    sentence_author sa1,
    #               sentence_author sa2
    #       WHERE   sa1.publication_id = sa2.publication_id
    #         AND   sa1.sentence_id = sa2.sentence_id
    #         AND   sa1.author_id != sa2.author_id
    #       """
    #   function: "And(sentence_author.sa1.is_true, sentence_author.sa2.is_true)"
    #   weight: "-10"  # should be a small negative weight..?
    # }

    ############# Sentence-level prediction ##############

    fs_sent_stats {
      input_query: """
          SELECT  sent.id as "sentence_author.id",
                  sent.is_true as "sentence_author.is_true",
                  (author_id || '-' || fname) as "f_doc_stats.fname"
          FROM    f_sentence_stats f, 
                  sentence_author sent
          WHERE   sent.sentence_id = f.sentence_id
            AND   sent.publication_id = f.publication_id
            AND (
                  (fname = 'num_chars' and fval >= 200) OR
                  (fname = 'num_words' and fval >= 30) 
                )
          """
      # AND (  
      #       sent.is_true = true OR
      #       f.publication_id in (select * from holdout_publications)
      #     )
      # This is bad: cannot learn negative features
      function: "IsTrue(sentence_author.is_true)"
      weight: "?(f_doc_stats.fname)"
    }
    fs_char_1gram {
      input_query: """
          SELECT  sent.id as "sentence_author.id",
                  sent.is_true as "sentence_author.is_true",
                  (author_id || '-' || ngram) as "f_char_1gram.ngram"
          FROM    f_char_1gram f, 
                  sentence_author sent
          WHERE   count > 10.0
            AND   sent.sentence_id = f.sentence_id
            AND   sent.publication_id = f.publication_id

          """
      function: "IsTrue(sentence_author.is_true)"
      weight: "?(f_char_1gram.ngram)"
    }
    fs_char_2gram {
      input_query: """
          SELECT  sent.id as "sentence_author.id",
                  sent.is_true as "sentence_author.is_true",
                  (author_id || '-' || ngram) as "f_char_2gram.ngram"
          FROM    f_char_2gram f, 
                  sentence_author sent
          WHERE   count > 3.0
            AND   sent.sentence_id = f.sentence_id
            AND   sent.publication_id = f.publication_id
          """
      function: "IsTrue(sentence_author.is_true)"
      weight: "?(f_char_2gram.ngram)"
    }
    fs_word_1gram {
      input_query: """
          SELECT  sent.id as "sentence_author.id",
                  sent.is_true as "sentence_author.is_true",
                  (author_id || '-' || ngram) as "f_word_1gram.ngram"
          FROM    f_word_1gram f, 
                  sentence_author sent
          WHERE   count > 0.0
            AND   sent.sentence_id = f.sentence_id
            AND   sent.publication_id = f.publication_id
          """
      function: "IsTrue(sentence_author.is_true)"
      weight: "?(f_word_1gram.ngram)"
    }
    fs_word_3gram {
      input_query: """
          SELECT  sent.id as "sentence_author.id",
                  sent.is_true as "sentence_author.is_true",
                  (author_id || '-' || ngram) as "f_word_3gram.ngram"
          FROM    f_word_3gram f, 
                  sentence_author sent
          WHERE   count > 0.0
            AND   sent.sentence_id = f.sentence_id
            AND   sent.publication_id = f.publication_id
          """
      function: "IsTrue(sentence_author.is_true)"
      weight: "?(f_word_3gram.ngram)"
    }
    fs_pos_1gram {
      input_query: """
          SELECT  sent.id as "sentence_author.id",
                  sent.is_true as "sentence_author.is_true",
                  (author_id || '-' || ngram || count) as "f_pos_1gram.ngram"
          FROM    f_pos_1gram f, 
                  sentence_author sent
          WHERE   count > 0.0
            AND   sent.sentence_id = f.sentence_id
            AND   sent.publication_id = f.publication_id
          """
      function: "IsTrue(sentence_author.is_true)"
      weight: "?(f_pos_1gram.ngram)"
    }
    fs_pos_2gram {
      input_query: """
          SELECT  sent.id as "sentence_author.id",
                  sent.is_true as "sentence_author.is_true",
                  (author_id || '-' || ngram) as "f_pos_2gram.ngram"
          FROM    f_pos_2gram f, 
                  sentence_author sent
          WHERE   count > 0.0
            AND   sent.sentence_id = f.sentence_id
            AND   sent.publication_id = f.publication_id
          """
      function: "IsTrue(sentence_author.is_true)"
      weight: "?(f_pos_2gram.ngram)"
    }
    fs_dep_1gram {
      input_query: """
          SELECT  sent.id as "sentence_author.id",
                  sent.is_true as "sentence_author.is_true",
                  (author_id || '-' || ngram) as "f_dep_1gram.ngram"
          FROM    f_dep_1gram f, 
                  sentence_author sent
          WHERE   count > 0.0
            AND   ngram not like 'dep%'
            AND   sent.sentence_id = f.sentence_id
            AND   sent.publication_id = f.publication_id
          """
      function: "IsTrue(sentence_author.is_true)"
      weight: "?(f_dep_1gram.ngram)"
    }

  }

}

