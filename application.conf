deepdive {

  # #############
  # CONFIGURATION
  # #############
  db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}  #"
    user: ${PGUSER}
    password: ${PGPASSWORD}
  }

  sampler.sampler_cmd: "util/sampler-dw-linux gibbs"
  # sampler.sampler_args: "-l 1000 -s 1 -i 1000 --alpha 0.01"
  sampler.sampler_args: "-l 0 -s 1 -i 0 --alpha 0.01"

  # pipeline.relearn_from: ""

  # ###########
  # CALIBRATION
  # ###########
  calibration.holdout_fraction: 0.25

  # ##############
  # FREE VARIABLES
  # ##############
  schema.variables {
    # publication_author.is_true: Boolean 
    # TODO
    sentence_author.is_true: Boolean
  }

  # ###########
  # DEBUGGING
  # ###########
  pipeline.run: "all"

  pipeline.pipelines.all: [
    # NLP extraction on all sentences
    # "ext_sentences_nlp",
    # "ext_sentence_author",
    # "ext_prepare_supervision", "ext_positive_example", "ext_negative_example",

    # Features
    # "ext_sentence_stats",
    "ext_char_1gram",
    "ext_char_2gram",
    "ext_word_1gram",
    "ext_word_3gram",
    "ext_pos_2gram",
    # "ext_doc_stats",
  ]
  pipeline.pipelines.test: ["ext_char_2gram"]


  # ##########
  # Extractors
  # ##########
  extraction.extractors {

    ########### 
    # Prepare tables before extraction:
    # corpus(id bigint): Contains all publication ids we care. 
    # authors(author_id bigint): Contains all author_id we care. 

    # Extract sentence NLP Tags from articles
    ext_sentences_nlp {
      input: """
          SELECT p.id AS publication_id,
                description
          FROM meta_publications p, corpus t
          WHERE p.id = t.id and 
            not exists (select * from sentences where document_id = p.id)
          ORDER BY publication_id ASC
        """
      output_relation: "sentences"
      udf: "bash "${APP_HOME}"/udf/nlp_extractor/run.sh -k publication_id -v description -l 20 -t 4"
      before: ${APP_HOME}"/udf/before_sentences.sh"
      input_batch_size: 10
      output_batch_size: 1000
      parallelism: ${PARALLELISM}
    }


    # Create the prediction matrix
    # size: 3,550,093
    # TODO Fix bigserial for faster grounding 
    # DISTRIBUTED BY (publication_id);
    ext_sentence_author {
      style: "sql_extractor"
      dependencies: ["ext_sentences_nlp"]
      sql: """
        DROP TABLE IF EXISTS sentence_author CASCADE;

        CREATE TABLE sentence_author (
            id bigserial primary key,
            sentence_id bigint,
            publication_id bigint,
            author_id bigint,
            is_true boolean
          );

        INSERT INTO sentence_author (sentence_id, publication_id, 
                author_id, is_true)
        SELECT  sentences.id AS sentence_id, 
                document_id AS publication_id, 
                authors.author_id,
                null::boolean is_true
          FROM  sentences, authors;
      """
    }

    ext_prepare_supervision {
      style: "sql_extractor"
      dependencies: ["ext_sentence_author"]
      sql:"""
        DROP TABLE IF EXISTS publication_authors CASCADE;
        CREATE TABLE publication_authors AS 
        SELECT p.*
        FROM meta_publication_authors p, corpus t 
        WHERE t.id = p.publication_id
        DISTRIBUTED BY (publication_id);
        """
    }
    # Set Single_author_papers as positive examples
    # 2119 positive examples
    ext_positive_example {
      style: "sql_extractor"
      dependencies: ["ext_prepare_supervision"]
      sql: """
        DROP TABLE IF EXISTS publication_author_count CASCADE;

        CREATE TABLE publication_author_count 
        AS 
          SELECT t.id AS publication_id, COUNT(author_id) AS num_authors FROM corpus t, publication_authors 
        WHERE t.id = publication_id GROUP BY (t.id) 
        DISTRIBUTED BY (publication_id);

        UPDATE  sentence_author 
           SET  is_true = true
          FROM  publication_author_count c,
                publication_authors a
         WHERE  a.publication_id = c.publication_id
           AND  c.publication_id = sentence_author.publication_id
           AND  a.author_id = sentence_author.author_id
           AND  c.num_authors = 1 ;
        
      """
    }

    # Set ALL non-authored papers as negative examples
    # 3539102 negative examples
    ext_negative_example {
      style: "sql_extractor"
      dependencies: ["ext_prepare_supervision"]
      sql: """
        UPDATE  sentence_author 
           SET  is_true = false
         WHERE  NOT EXISTS (
            SELECT  * 
            FROM    publication_authors a
            WHERE   a.publication_id =  sentence_author.publication_id
              AND   a.author_id = sentence_author.author_id
        );
      """
    }

    ext_sentence_stats {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp"]
      input: """
        select id, document_id, sentence, words
        from sentences
      """
      output_relation: "f_sentence_stats"
      udf: ${APP_HOME}"/udf/ext_sentence_stats.py"
      before: ${APP_HOME}"/udf/before_sentence_stats.sh"
    }

    # Select character Ngrams (N is 3rd input in the query / before / output_relation)
    ext_char_1gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp"]
      input: """
        select id, document_id, sentence, 1
        from sentences
      """
      output_relation: "f_char_1gram"
      udf: ${APP_HOME}"/udf/ext_char_ngram.py"
      before: ${APP_HOME}"/udf/before_char_ngram.sh 1"
    }

    # Select character Ngrams (N is 3rd input in the query / before / output_relation)
    ext_char_2gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp"]
      input: """
        select id, document_id, sentence, 2
        from sentences
      """
      output_relation: "f_char_2gram"
      udf: ${APP_HOME}"/udf/ext_char_ngram.py"
      before: ${APP_HOME}"/udf/before_char_ngram.sh 2"
    }

    # Select character Ngrams (N is 3rd input in the query)
    ext_word_1gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp"]
      input: """
        select id, document_id, words, 1
        from sentences
      """
      output_relation: "f_word_1gram"
      udf: ${APP_HOME}"/udf/ext_word_ngram.py"
      before: ${APP_HOME}"/udf/before_word_ngram.sh 1"
    }

    # Select word Ngrams (N is 3rd input in the query)
    ext_word_3gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp"]
      input: """
        select id, document_id, words, 3
        from sentences
      """
      output_relation: "f_word_3gram"
      udf: ${APP_HOME}"/udf/ext_word_ngram.py"
      before: ${APP_HOME}"/udf/before_word_ngram.sh 3"
    }

    # Select pos Ngrams (N is 3rd input in the query)
    ext_pos_2gram {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp"]
      input: """
        select id, document_id, pos_tags, 2
        from sentences
      """
      output_relation: "f_pos_2gram"
      udf: ${APP_HOME}"/udf/ext_word_ngram.py"
      before: ${APP_HOME}"/udf/before_pos_ngram.sh 2"
    }

    ############# Document-level ##############

    # Doc length, # words, avg length of words.
    ext_doc_stats {
      style: "plpy_extractor"
      dependencies: ["ext_sentences_nlp"]
      input: """
        select id, datestamp, title, description 
        from corpus natural join meta_publications
      """
      output_relation: "f_doc_stats"
      udf: ${APP_HOME}"/udf/ext_doc_stats.py"
      before: ${APP_HOME}"/udf/before_doc_stats.sh"
    }

    # # Set ALL non-authored papers as negative examples
    # # 3539102 negative examples
    # ext_coauthorship {
    #   style: "sql_extractor"
    # }
  }

  # ###############
  # Inference Rules
  # ###############
  inference.factors {

    # f_coauthor {
    #   input_query: """
    #   SELECT  a1.id as "sentence_author.a1.id",
    #           a1.is_true as "sentence_author.a1.is_true",
    #           a2.id as "sentence_author.a2.id",
    #           a2.is_true as "sentence_author.a2.is_true"
    #     FROM  sentence_author a1,
    #           sentence_author a2
    #    WHERE  a1.publication_id = a2.publication_id

    #   """
    # }
  }

}

# STATS
    # 2265 distinct char 2grams
    # 109977 distinct char 5grams
    # 16709 words
    # 191637 word 3grams
    # 1188 pos 2grams

